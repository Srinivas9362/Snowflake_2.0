ğŸ§­ DOMAIN 1.0 â€” DATA MOVEMENT

Goal: You should be able to load, ingest, transform, and share data efficiently using Snowflakeâ€™s ecosystem.

ğŸ”¹ STEP 1: Data Loading Basics (1.1)
Topics to Learn:

Data Loading Considerations

File size (optimal: 100â€“250 MB compressed)

File format (CSV, JSON, Parquet, Avro, ORC, XML)

Compression (GZIP, BZIP2, SNAPPY)

Network and warehouse sizing (compute cost)

Parallel loading (multi-file load for performance)

Error handling (ON_ERROR clause)

Data Loading Features & Impacts

COPY INTO command

Data validation and transformation during load

Impact on performance, storage, and cost

Time travel and cloning effects on load

ğŸ“˜ Start here:

Learn COPY INTO in depth (from internal & external stages).

Practice loading data from local files, S3, and Azure Blob.

ğŸ”¹ STEP 2: Ingesting Various Data Formats (1.2)
Topics to Learn:

File Formats

Create file formats using CREATE FILE FORMAT

Parameters: FIELD_DELIMITER, SKIP_HEADER, COMPRESSION, etc.

Data Types by Format

Structured: CSV, Parquet

Semi-structured: JSON, XML, Avro

Unstructured: images, PDFs, etc. (stored via external stages)

Stages

Internal stages: user, table, named stages

External stages: S3, GCS, Azure

LIST, PUT, GET, and REMOVE commands

ğŸ“˜ Hands-on:

Create FILE FORMAT objects.

Load JSON & Parquet into VARIANT columns.

Query semi-structured data with FLATTEN().

ğŸ”¹ STEP 3: Troubleshooting Ingestion (1.3)
Topics to Learn:

Common ingestion issues:

File format mismatch

Permissions (stage or role-based)

Incorrect COPY syntax

Corrupted files

Duplicate file loads

Debugging methods:

View LOAD_HISTORY()

Use VALIDATE_PIPE_LOAD()

Check stage file access

Understand the meaning of error codes

ğŸ“˜ Hands-on:
Use VALIDATION_MODE = RETURN_ERRORS and ON_ERROR options.

ğŸ”¹ STEP 4: Continuous Data Pipelines (1.4)
Topics to Learn:

Stages â€“ where raw data lands.

Streams â€“ change tracking (CDC).

Tasks â€“ automation (scheduled or event-driven SQL).

Snowpipe

Auto-ingest (event-based via cloud notification)

REST API (manual trigger)

Snowpipe Streaming

Near real-time ingestion (Kafka/Snowpark streaming)

ğŸ“˜ Hands-on:

Create a stream + task pipeline for incremental loads.

Compare Snowpipe vs. Tasks for automation.

Practice auto-ingest setup on AWS S3.

ğŸ”¹ STEP 5: Data Pipeline Design (1.5)
Topics to Learn:

Pipeline Types

Batch vs. Streaming vs. Micro-batch.

ELT using Snowflakeâ€™s compute.

User Defined Functions (UDFs)

SQL UDFs

JavaScript UDFs

Python UDFs (via Snowpark)

Snowflake SQL API

Query submission via API

Job monitoring and status retrieval

Snowpark Pipelines

Write transformations using Python, Scala, or Java

DataFrame API

Deploy using stored procedures or tasks

ğŸ“˜ Hands-on:

Write a simple Python Snowpark pipeline.

Create and call SQL/JS UDFs.

ğŸ”¹ STEP 6: Connectors (1.6)
Topics to Learn:

Kafka Connector

Snowflake Kafka Sink Connector

Auto-ingest streaming messages

Topic â†’ Table mapping

Spark Connector

Read/write Snowflake data via Spark jobs

sfURL, sfDatabase, sfWarehouse, etc.

Python Connector

snowflake.connector library

Execute queries, load/unload data

ğŸ“˜ Hands-on:

Write Python code to connect & insert data into Snowflake.

ğŸ”¹ STEP 7: Data Sharing (1.7)
Topics to Learn:

Data Shares

Secure data sharing (no data copy)

CREATE SHARE, ADD DATABASE, GRANT USAGE

Views

Secure views

Row-level security (RLS)

Snowflake Marketplace

Public & private listings

Listings

Sharing datasets as listings for organizations

ğŸ“˜ Hands-on:

Create a secure view and share with another account.

ğŸ”¹ STEP 8: External Tables & Unload (1.8)
Topics to Learn:

External Tables

Define tables over files in S3, Azure, GCS

Used for querying raw data without loading

REFRESH command for metadata updates

Iceberg Tables

For open table formats (ACID + external storage)

Schema Evolution

How Snowflake handles column changes in external tables

Unload Data

Use COPY INTO @stage to export data from Snowflake to S3

ğŸ“˜ Hands-on:

Create and query an external table on S3.

Practice COPY INTO unloads as JSON and CSV.

ğŸ§© Recommended Learning Flow (Simplified)
---
| Order | Topic                             | Skill Level           | Why                             |
| :---- | :-------------------------------- | :-------------------- | :------------------------------ |
| 1ï¸âƒ£   | Data Loading Concepts             | Beginner              | Foundation for everything else  |
| 2ï¸âƒ£   | File Formats & Stages             | Beginner              | Essential for ingestion         |
| 3ï¸âƒ£   | Troubleshooting Ingestion         | Intermediate          | Real-world importance           |
| 4ï¸âƒ£   | Streams, Tasks, Snowpipe          | Intermediate          | Automation backbone             |
| 5ï¸âƒ£   | UDFs, Snowpark, SQL API           | Intermediateâ€“Advanced | Coding/data transformation      |
| 6ï¸âƒ£   | Connectors (Kafka, Spark, Python) | Advanced              | Integration with external tools |
| 7ï¸âƒ£   | Data Sharing                      | Advanced              | Cross-account collaboration     |
| 8ï¸âƒ£   | External Tables & Unload          | Advanced              | Hybrid & open data architecture |

ğŸ§­ Snowflake Advanced Data Engineer Certification â€” Domain 1.0: Data Movement

| **S.No** | **Topic**                                                              |    **Level**    |
| :------: | :--------------------------------------------------------------------- | :-------------: |
|     1    | Databases                                                              |   ğŸŸ¢ Beginner   |
|     2    | Schemas and Tables (basic structure for loading data)                  |   ğŸŸ¢ Beginner   |
|     3    | Data Loading Concepts                                                  |   ğŸŸ¢ Beginner   |
|     4    | COPY INTO command                                                      |   ğŸŸ¢ Beginner   |
|     5    | Data Loading Considerations (file size, compression, performance)      |   ğŸŸ¢ Beginner   |
|     6    | Data Loading Features & Impacts (error handling, parallel loads)       |   ğŸŸ¢ Beginner   |
|     7    | File Formats â€” CSV, JSON, Parquet, Avro, ORC, XML                      |   ğŸŸ¢ Beginner   |
|     8    | Create and Manage File Formats (`CREATE FILE FORMAT`)                  |   ğŸŸ¢ Beginner   |
|     9    | Structured Data Ingestion                                              |   ğŸŸ¢ Beginner   |
|    10    | Semi-Structured Data Ingestion (JSON, Avro, XML)                       |   ğŸŸ¢ Beginner   |
|    11    | Unstructured Data Handling (images, documents)                         |   ğŸŸ¢ Beginner   |
|    12    | Internal Stages (User, Table, Named)                                   |   ğŸŸ¢ Beginner   |
|    13    | External Stages (S3, Azure, GCS)                                       |   ğŸŸ¢ Beginner   |
|    14    | Stage Commands â€” PUT, GET, LIST, REMOVE                                |   ğŸŸ¢ Beginner   |
|    15    | Implementation of Stages and File Formats                              |   ğŸŸ¢ Beginner   |
|    16    | Creating and Managing Views                                            |   ğŸŸ¢ Beginner   |
|    17    | Using Secure Views                                                     |   ğŸŸ¢ Beginner   |
|    18    | Row-Level Security (basic understanding)                               |   ğŸŸ¢ Beginner   |
|    19    | Troubleshooting Data Ingestion                                         | ğŸŸ¡ Intermediate |
|    20    | Identifying Causes of Ingestion Errors                                 | ğŸŸ¡ Intermediate |
|    21    | Resolving Ingestion Errors                                             | ğŸŸ¡ Intermediate |
|    22    | Tasks â€” Scheduling and Automation                                      | ğŸŸ¡ Intermediate |
|    23    | Streams â€” Change Data Capture (CDC)                                    | ğŸŸ¡ Intermediate |
|    24    | Snowpipe â€” Continuous Loading (Auto-ingest & REST API)                 | ğŸŸ¡ Intermediate |
|    25    | Designing Continuous Data Pipelines (Stages + Tasks + Streams + Pipes) | ğŸŸ¡ Intermediate |
|    26    | Differentiating Pipeline Types (Batch vs Streaming)                    | ğŸŸ¡ Intermediate |
|    27    | Creating SQL and JavaScript UDFs                                       | ğŸŸ¡ Intermediate |
|    28    | Python Connector Basics (`snowflake.connector`)                        | ğŸŸ¡ Intermediate |
|    29    | Unloading Data using `COPY INTO @stage`                                | ğŸŸ¡ Intermediate |
|    30    | General Table Management (CREATE, ALTER, DROP, REFRESH)                | ğŸŸ¡ Intermediate |
|    31    | Implementing Row-Level Filtering                                       | ğŸŸ¡ Intermediate |
|    32    | Implementing Secure Data Sharing (basic)                               | ğŸŸ¡ Intermediate |
|    33    | Snowpipe Streaming (real-time ingestion)                               |   ğŸŸ  Advanced   |
|    34    | Snowflake SQL API (query submission and monitoring)                    |   ğŸŸ  Advanced   |
|    35    | Creating Data Pipelines in Snowpark (Python, Scala, Java)              |   ğŸŸ  Advanced   |
|    36    | Kafka Connector (Snowflake Sink)                                       |   ğŸŸ  Advanced   |
|    37    | Spark Connector (Read/Write integration)                               |   ğŸŸ  Advanced   |
|    38    | Advanced Python Connector (Parameterized Queries, Error Handling)      |   ğŸŸ  Advanced   |
|    39    | Implementing Secure Data Shares across Accounts                        |   ğŸŸ  Advanced   |
|    40    | Sharing Data via Snowflake Marketplace                                 |   ğŸŸ  Advanced   |
|    41    | Sharing Data using Listings (Public/Private)                           |   ğŸŸ  Advanced   |
|    42    | Managing External Tables (S3, GCS, Azure)                              |   ğŸŸ  Advanced   |
|    43    | Managing Schema Evolution in External Tables                           |   ğŸŸ  Advanced   |
|    44    | Managing Iceberg Tables (Open Table Format)                            |   ğŸŸ  Advanced   |
|    45    | Designing Hybrid Data Architectures (Internal + External Tables)       |    ğŸ”µ Expert    |
|    46    | Optimizing Data Pipelines (Performance, Cost, and Concurrency)         |    ğŸ”µ Expert    |
|    47    | Advanced Snowpipe + Stream Integration for Real-Time Analytics         |    ğŸ”µ Expert    |
